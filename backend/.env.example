# App
APP_NAME=MindAtlas API
APP_ENV=development
DEBUG=true

# API
API_PREFIX=/api

# Database (PostgreSQL)
# Reference default: postgresql://postgres:postgres@localhost:5432/mindatlas
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/mindatlas

# CORS
# Comma-separated list; leave empty to disable CORS middleware.
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# MinIO (S3-compatible object storage for attachments)
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=
MINIO_SECRET_KEY=
MINIO_BUCKET=mindatlas
MINIO_SECURE=false

# AI (runtime config, optional)
AI_PROVIDER=openai
AI_API_KEY=
AI_BASE_URL=https://api.openai.com/v1
AI_MODEL=gpt-4o-mini

# AI Provider storage (Fernet encryption key for API keys)
# Generate via: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
AI_PROVIDER_FERNET_KEY=

# LightRAG (knowledge graph indexing)
LIGHTRAG_ENABLED=false
LIGHTRAG_WORKER_ENABLED=false
LIGHTRAG_WORKER_POLL_INTERVAL_MS=2000
LIGHTRAG_WORKER_BATCH_SIZE=50
LIGHTRAG_WORKER_MAX_ATTEMPTS=6
LIGHTRAG_WORKER_LOCK_TTL_SEC=300
LIGHTRAG_WORKING_DIR=./lightrag_storage
LIGHTRAG_WORKSPACE=
LIGHTRAG_GRAPH_STORAGE=Neo4JStorage
LIGHTRAG_LLM_MODEL=gpt-4o-mini
# Advanced (OpenAI-compatible): set MODEL/HOST/KEY in one value (JSON)
# LIGHTRAG_LLM_MODEL='{"MODEL":"gpt-4o-mini","HOST":"https://api.openai.com/v1","KEY":"sk-..."}'
# Or override host/key separately:
# LIGHTRAG_LLM_HOST=https://api.openai.com/v1
# LIGHTRAG_LLM_KEY=sk-...
LIGHTRAG_EMBEDDING_MODEL=text-embedding-3-small
# Advanced (OpenAI-compatible): set MODEL/HOST/KEY in one value (JSON)
# LIGHTRAG_EMBEDDING_MODEL='{"MODEL":"text-embedding-3-small","HOST":"https://api.openai.com/v1","KEY":"sk-..."}'
# Or override host/key separately:
# LIGHTRAG_EMBEDDING_HOST=https://api.openai.com/v1
# LIGHTRAG_EMBEDDING_KEY=sk-...
LIGHTRAG_EMBEDDING_DIM=1536

# LightRAG Query API (Phase 5)
LIGHTRAG_AI_KEY_SOURCE=env_or_db
LIGHTRAG_QUERY_TIMEOUT_SEC=60
LIGHTRAG_QUERY_MAX_CONCURRENCY=4
LIGHTRAG_QUERY_CACHE_TTL_SEC=3600
LIGHTRAG_QUERY_CACHE_MAXSIZE=128

# LightRAG Language (optional)
# Controls prompt language for summarization/entity extraction inside LightRAG.
# Example: English | Chinese
LIGHTRAG_SUMMARY_LANGUAGE=Chinese

# LightRAG Rerank (optional)
# Standard rerank API (vLLM/LiteLLM compatible). If MODEL+HOST are set, rerank is enabled automatically.
# If HOST endswith "/v1", backend will append "/rerank" (so "/v1/rerank" is also fine).
LIGHTRAG_RERANK_MODEL=
LIGHTRAG_RERANK_HOST=
LIGHTRAG_RERANK_KEY=
LIGHTRAG_RERANK_TIMEOUT_SEC=15
# standard | aliyun
LIGHTRAG_RERANK_REQUEST_FORMAT=standard
LIGHTRAG_RERANK_ENABLE_CHUNKING=false
LIGHTRAG_RERANK_MAX_TOKENS_PER_DOC=480
LIGHTRAG_MIN_RERANK_SCORE=0.0

# Neo4j (required when LIGHTRAG_ENABLED=true and using Neo4JStorage)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=
NEO4J_DATABASE=neo4j

# Docling Worker (attachment parsing for knowledge graph)
# Parses PDF, Office docs, images (OCR) and indexes text to knowledge graph
DOCLING_WORKER_ENABLED=false
DOCLING_WORKER_POLL_INTERVAL_MS=2000
DOCLING_WORKER_BATCH_SIZE=1
DOCLING_WORKER_MAX_ATTEMPTS=3
DOCLING_WORKER_LOCK_TTL_SEC=600
DOCLING_MAX_FILE_SIZE_MB=100
DOCLING_MAX_PDF_PAGES=500

# Docling OCR (RapidOCR, CPU optimized)
DOCLING_OCR_ENABLED=true
DOCLING_OCR_FORCE_FULL_PAGE_OCR=false
DOCLING_OCR_LANGS=english,chinese

# Docling Picture Description (remote VLM via OpenAI-compatible API)
# Enable only if you have a VLM that supports image_url data URIs
DOCLING_PICTURE_DESCRIPTION_ENABLED=false
# Accepts base URL or full endpoint (auto-normalized to /v1/chat/completions)
# DOCLING_PICTURE_DESCRIPTION_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
# DOCLING_PICTURE_DESCRIPTION_API_KEY=sk-xxx
# DOCLING_PICTURE_DESCRIPTION_MODEL=qwen-vl-max
DOCLING_PICTURE_DESCRIPTION_PROMPT=请简要描述这张图片的内容；如果是图表请提取关键数据。
DOCLING_PICTURE_DESCRIPTION_TIMEOUT_SEC=60
DOCLING_PICTURE_DESCRIPTION_CONCURRENCY=1
# Optional JSON merged into request payload (e.g. {"max_tokens":256})
# DOCLING_PICTURE_DESCRIPTION_PARAMS_JSON=

# Server
HOST=0.0.0.0
PORT=8000
